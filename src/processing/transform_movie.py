from pyspark.sql import SparkSession
from pyspark.sql.functions import col, datediff, current_date, when, lit, to_date

def get_spark_session():
    return SparkSession.builder \
        .appName("Movie Cine-Pulse Transformation") \
        .config("hive.metastore.uris", "thrift://hive-metastore:9083") \
        .enableHiveSupport() \
        .getOrCreate()

def main():
    spark = get_spark_session()
    
    # 1. ƒê·ªçc 2 ngu·ªìn d·ªØ li·ªáu t·ª´ Data Lake
    # L∆∞u √Ω: Ph·∫£i drop ngay c√°c c·ªôt partition c≈© ƒëi ƒë·ªÉ tr√°nh tr√πng l·∫∑p/xung ƒë·ªôt v·ªÅ sau
    df_buzz = spark.read.parquet("hdfs://namenode:9000/datalake/social_buzz_movie") \
                   .drop("year", "month", "day") 
    
    df_meta = spark.read.parquet("hdfs://namenode:9000/datalake/movies_metadata") \
                   .drop("year", "month", "day")

    # 2. JOIN d·ªØ li·ªáu
    # Join theo t√™n phim (movie_name)
    # V√Ä QUAN TR·ªåNG: Drop c√°c c·ªôt tr√πng l·∫∑p sau khi join
    df_joined = df_buzz.join(df_meta, df_buzz.movie_name == df_meta.movie_name, "inner") \
                       .drop(df_meta.movie_name) \
                       .drop(df_meta.movie_id)  # <-- TH√äM D√íNG N√ÄY: B·ªè movie_id c·ªßa b·∫£ng b√™n ph·∫£i (meta) ƒëi

    # 3. Logic V√≤ng ƒê·ªùi (Lifecycle Logic)
    # T√≠nh kho·∫£ng c√°ch ng√†y: Ng√†y th·∫£o lu·∫≠n - Ng√†y c√¥ng chi·∫øu
    # L∆∞u √Ω: timestamp trong buzz l√† string/timestamp, c·∫ßn ƒë·∫£m b·∫£o format
    df_calced = df_joined.withColumn("days_diff", 
                                     datediff(to_date(col("timestamp")), to_date(col("release_date"))))

    # 4. G·∫Øn nh√£n t·ª± ƒë·ªông (Auto-Tagging)
    # < -30: Early Hype (Tin ƒë·ªìn)
    # -7 ƒë·∫øn +7: Prime Time (C√¥ng chi·∫øu - Quan tr·ªçng nh·∫•t)
    # > 30: Cooling Down (H·∫øt hot)
    df_final = df_calced.withColumn("lifecycle_tag",
        when(col("days_diff") < -30, "Early Hype")
        .when((col("days_diff") >= -7) & (col("days_diff") <= 7), "Prime Time")
        .when(col("days_diff") > 30, "Cooling Down")
        .otherwise("Normal Run")
    )

    # 5. L∆∞u v√†o Data Warehouse
    print("üíæ Dang ghi ket qua vao Hive Table: movie_cine_pulse ...")
    df_final.write.mode("overwrite").saveAsTable("social_trend_db.movie_cine_pulse")
    
    print("‚úÖ MOVIE TRANSFORMATION DONE!")
    spark.stop()

if __name__ == "__main__":
    main()